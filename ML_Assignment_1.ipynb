{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Assignment 1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_T7i9268lRt"
      },
      "source": [
        "# a = [ ] \n",
        "\n",
        "# while(1): a.append('1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzyeusMB0dPB"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfw-_vYg1Fmk"
      },
      "source": [
        "Model Implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nERUwTsQ1tyi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1b3633b-4b1d-4974-bd1d-56ced3eed78f"
      },
      "source": [
        "!wget -N http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-21 08:32:14--  http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3127238 (3.0M) [application/x-gzip]\n",
            "Saving to: ‘review_polarity.tar.gz’\n",
            "\n",
            "review_polarity.tar 100%[===================>]   2.98M   979KB/s    in 3.2s    \n",
            "\n",
            "2021-04-21 08:32:17 (947 KB/s) - ‘review_polarity.tar.gz’ saved [3127238/3127238]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlulPtGJ2xnp"
      },
      "source": [
        "## PARSING DATA\n",
        "\n",
        "# Opening files\n",
        "files = !tar xvzf review_polarity.tar.gz\n",
        "# Files into list\n",
        "files = list(files)\n",
        "\n",
        "X_raw = []\n",
        "y_labels = []\n",
        "\n",
        "# negative files\n",
        "\n",
        "for file in files[:1000]:\n",
        "  with open(file, 'r') as f: \n",
        "    filecontent = f.read()\n",
        "    X_raw.append(filecontent)\n",
        "    y_labels.append(-1)\n",
        "\n",
        "# positive files\n",
        "for file in files[1000:2000]:\n",
        "  with open(file, 'r') as f:\n",
        "    filecontent = f.read()\n",
        "    X_raw.append(filecontent)\n",
        "    y_labels.append(1)\n",
        "\n",
        "# X_raw[0]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSpGU7BWSVgk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ff3a90-57ef-469a-adac-8b391e0fd3fd"
      },
      "source": [
        "## TOKENIZATION\n",
        "\n",
        "# list of words (all vocab)\n",
        "ordered_vocab = []\n",
        "stripped_docs = []\n",
        "\n",
        "for review in X_raw:\n",
        "  review.strip()\n",
        "  review.replace('\\n', '')\n",
        "  stripped_docs.append(review)\n",
        "  review = review.split(' ')\n",
        "  ordered_vocab.extend(review)\n",
        "\n",
        "# set containing unique words - O(1) when using 'in' operator on sets...\n",
        "vocab = set(ordered_vocab)\n",
        "len(vocab)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVK9yhEZSgwe"
      },
      "source": [
        "## LOOKUP TABLES ---> TOKENS : FEATURE NUMBERS\n",
        "\n",
        "lut = dict()\n",
        "for i, word in enumerate(ordered_vocab):\n",
        "  lut[word] = i\n",
        "\n",
        "# Example:\n",
        "\n",
        "# for word in tokenized_sents[0]:\n",
        "#   if word in vocab:\n",
        "#     print(\"'%s' is represented as feature dimension %i\" %(word, lut[word]))\n",
        "#   else:\n",
        "#     print(\"'%s' is not in the vocabulary\" % word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjThvhr6JfxY"
      },
      "source": [
        "# review --> vector (array), each element in the array --> 0 , 1\n",
        "\n",
        "# list of arrays\n",
        "binary_BOW = []\n",
        "\n",
        "# Traverse through each review and check if each word in vocab is in review and create array of 0s and 1s\n",
        "  \n",
        "for doc in stripped_docs:\n",
        "    vector = []\n",
        "    for word in vocab:\n",
        "        if word in doc:\n",
        "            vector.append(1)\n",
        "        else:\n",
        "            vector.append(0)\n",
        "    vector = np.array(vector)\n",
        "    binary_BOW.append(vector)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFqi6oWOD3iR"
      },
      "source": [
        "X = binary_BOW\n",
        "y = y_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np5G1eaLFc7-"
      },
      "source": [
        "Part 3: Mathematical Framework..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smVSCpC5Fhrr"
      },
      "source": [
        "## generate 'random' hyperplane model\n",
        "\n",
        "n_dim = len(binary_BOW[0])\n",
        "init_parameter_vector = np.asarray([np.random.randint(-9, 9, size=n_dim+1)])\n",
        "omega = np.transpose(init_parameter_vector)\n",
        "print(\"Parameter vector is transposed! Next step, add pseudo inputs and dot product with data inputs!\")\n",
        "\n",
        "## insert pseudo input in each input\n",
        "\n",
        "pseudo_input = np.ones((len(X), 1))\n",
        "\n",
        "# adding the pseudo inputs to X\n",
        "\n",
        "print(\"Current Length of n_dim --> \", len(binary_BOW[0]))\n",
        "X_pseudo = np.c_[X, pseudo_input]\n",
        "print(\"New Length of number of dimensions --> \", len(X_pseudo[0]))\n",
        "print('')\n",
        "\n",
        "# shapes....\n",
        "\n",
        "print(\"Shapes are fine now...\")\n",
        "print(omega.shape)\n",
        "print(X_pseudo[0].shape)\n",
        "\n",
        "# shuffle train data\n",
        "X_train = np.concatenate((X_pseudo[:800], X_pseudo[1000:1800]))\n",
        "y_train = y_labels[:800] + y_labels[1000:1800]\n",
        "\n",
        "print(len(X_train), len(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rWnEDtciV1T"
      },
      "source": [
        "# predicted_results = np.asarray([np.sign(np.vdot(omega, arr)) for arr in X_pseudo])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnMODGs3pHEx"
      },
      "source": [
        "from numpy.linalg import norm\n",
        "\n",
        "reguliser_dampening = 0.0001\n",
        "norm_omega = norm(omega)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XODjypg71RKk"
      },
      "source": [
        "summation = 0\n",
        "\n",
        "for i, arr in enumerate(X_train):\n",
        "    summation += max(0, 1 - (np.multiply(y_train[i], np.vdot(omega, arr))))\n",
        "\n",
        "print(summation)\n",
        "# print(len(X_pseudo), len(predicted_results))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvLVjPkjpefr"
      },
      "source": [
        "current_hinge_loss = (reguliser_dampening/2) * norm_omega**2 + summation\n",
        "\n",
        "\n",
        "# first omega...\n",
        "current_hinge_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD2G5cvIqpoa"
      },
      "source": [
        "gd_summation = 0\n",
        "learning_rate = 0.1\n",
        "\n",
        "\n",
        "for i, label in enumerate(y_train):\n",
        "    if np.multiply(label, np.vdot(omega, X_train[i])) <= 1:\n",
        "        gd_summation += -(np.multiply(label, X_train[i]))\n",
        "        \n",
        "\n",
        "gradient = reguliser_dampening * omega + gd_summation\n",
        "\n",
        "new_omega = omega - (learning_rate * gradient)\n",
        "\n",
        "new_omega"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7c1ejFF2UtX"
      },
      "source": [
        "summation = np.zeros(len(X_train[0]))\n",
        "\n",
        "for i, arr in enumerate(X_train[:100]):\n",
        "    summation += max(0, 1 - (np.multiply(y_train[i], np.vdot(new_omega, arr))))\n",
        "\n",
        "current_hinge_loss = (reguliser_dampening/2) * norm(new_omega)**2 + summation\n",
        "\n",
        "current_hinge_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H43oGIXd1Hag"
      },
      "source": [
        "\n",
        " ## The below class will be used to finalize the model...\n",
        " \n",
        " class Model:\n",
        "  def __init__(self, learning_rate, etc):\n",
        "    learning_rate = learning_rate\n",
        "    etc = etc\n",
        "  \n",
        "  def fit(self, X, y):\n",
        "    pass\n",
        "\n",
        "  def predict(self, X):\n",
        "    pass\n",
        "  \n",
        "  def score(self, X, y):\n",
        "    pass\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}